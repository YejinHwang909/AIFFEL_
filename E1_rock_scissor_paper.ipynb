{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funny-exhaust",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "humanitarian-employment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print (\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compatible-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 35x35 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(35,35)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 resize 후 저장\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 resize 후 저장\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "south-import",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 resize 후 저장\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "accredited-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 35, 35, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=35\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "younger-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨:',y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-windsor",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "stretch-singapore",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 33, 33, 256)       7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 893,578\n",
      "Trainable params: 893,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "#seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#하이퍼파라미터들\n",
    "n_channel_1=256\n",
    "n_channel_2=256\n",
    "n_dense=128\n",
    "n_train_epoch=30\n",
    "\n",
    "#딥러닝 네트워크 모델 설계하기\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(35,35,3)))\n",
    "model.add(keras.layers.MaxPool2D(3,3))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((3,3)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-switzerland",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "extreme-uzbekistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reshape - x_train_reshaped shape: (300, 35, 35, 3)\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 13ms/step - loss: 1.7069 - accuracy: 0.2670\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.1810 - accuracy: 0.3091\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1113 - accuracy: 0.3285\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0864 - accuracy: 0.3596\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0617 - accuracy: 0.4243\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1207 - accuracy: 0.4532\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0150 - accuracy: 0.5793\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9096 - accuracy: 0.6078\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9728 - accuracy: 0.5246\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7635 - accuracy: 0.6915\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5771 - accuracy: 0.8368\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4572 - accuracy: 0.8703\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3822 - accuracy: 0.8768\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3124 - accuracy: 0.9014\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2283 - accuracy: 0.9455\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2076 - accuracy: 0.9555\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1327 - accuracy: 0.9884\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1285 - accuracy: 0.9630\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0938 - accuracy: 0.9862\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0782 - accuracy: 0.9916\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9870\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0783 - accuracy: 0.9856\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0674 - accuracy: 0.9879\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9935\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9920\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9966\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9935\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9956\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9914\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5e3aa8d50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped=x_train_norm.reshape(-1, 35, 35, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-alberta",
   "metadata": {},
   "source": [
    "# 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "australian-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "#테스트용 이미지 resize 하기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "compatible-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "traditional-slide",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9335 - accuracy: 0.6067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9335184693336487, 0.6066666841506958]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_reshaped=x_test_norm.reshape(-1, 35, 35, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "model.evaluate(x_test_reshaped, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-world",
   "metadata": {},
   "source": [
    "# conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-democracy",
   "metadata": {},
   "source": [
    "## 요약 \n",
    "\n",
    "* 데이터 불러오기 + resize 하기 : \n",
    "    훈련할 이미지들을 열고 resize 해서 다시 저장 후 numpy의 array에 이미지들을 복사했다.\n",
    "\n",
    "* 딥러닝 네트워크 설계하기 : \n",
    "    여러 레이어들을 중첩해서 네트워크를 설계했다. 네트워크에 쓰이는 여러 값들을 하이어파라미터로 지정해서 조절했다.\n",
    "\n",
    "* 딥러닝 네트워크 학습시키기 : \n",
    "    고급경사하강법 중 아담을 이용하여 딥러닝 네트워크를 학습시켰다.\n",
    "\n",
    "* 테스트하기 : \n",
    "    다른 사람의 가위바위보 이미지들을 이용해서 정확도를 산출했다. \n",
    "\n",
    "## 회고\n",
    "    test accuracy가 60%이상이 되도록 하는 것이 생각보다 어려웠다. 먼저 이미지 사이즈를 35X35로 늘리고, 하이어파라미터들의 값을 무조건 늘리는 식으로 조절했다. 하지만 n_train_epoch를 40으로 바꿨을 때 30일 때보다 더 정확도가 낮아진다는 사실을 알고 무조건 늘리는게 답은 아니라는 생각을 했다. 따라서 어느 한 파라미터를 많이 올리기 보다는 다같이 조금씩 올리는 방식으로 했고, 하이어 파라미터 뿐만 아니라 maxpooling의 pool size도 3X3으로 늘렸다. 그리고 다른 값들은 코드를 수정하는 일이 없었는데, 이미지 사이즈를 조절했을 때 다른 부분의 코드들을 수정해야 해서 그 점이 조금 어려웠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
