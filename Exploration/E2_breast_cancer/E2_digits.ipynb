{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assumed-convention",
   "metadata": {},
   "source": [
    "# (1) 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-valentine",
   "metadata": {},
   "source": [
    "# (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exposed-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 준비\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-thirty",
   "metadata": {},
   "source": [
    "# (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "based-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "#Feature Data 지정하기\n",
    "digits_data=digits.data\n",
    "\n",
    "#LabelData 지정하기\n",
    "digits_label=digits.target\n",
    "\n",
    "#Taget Names 출력해 보기\n",
    "print(digits.target_names)\n",
    "\n",
    "#데이터 Describe 해 보기\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-stability",
   "metadata": {},
   "source": [
    "# (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nonprofit-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-vintage",
   "metadata": {},
   "source": [
    "# (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "variable-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.80      0.86      0.83        42\n",
      "           2       0.79      0.85      0.82        40\n",
      "           3       0.86      0.91      0.89        34\n",
      "           4       0.83      0.92      0.87        37\n",
      "           5       0.87      0.96      0.92        28\n",
      "           6       0.93      0.93      0.93        28\n",
      "           7       0.93      0.79      0.85        33\n",
      "           8       0.91      0.67      0.77        43\n",
      "           9       0.74      0.78      0.76        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.87      0.87      0.86       360\n",
      "weighted avg       0.87      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree 사용\n",
    "decision_tree = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incomplete-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.91      1.00      0.95        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.97      1.00      0.99        34\n",
      "           4       0.92      0.97      0.95        37\n",
      "           5       0.90      1.00      0.95        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.81      0.90        43\n",
      "           9       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest 사용\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "voluntary-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM 사용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "congressional-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.87      0.98      0.92        42\n",
      "           2       0.97      0.97      0.97        40\n",
      "           3       0.97      0.94      0.96        34\n",
      "           4       0.97      0.97      0.97        37\n",
      "           5       0.97      1.00      0.98        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.95      0.86      0.90        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier 사용\n",
    "sgd_model=SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broke-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression 사용\n",
    "logistic_model = LogisticRegression(max_iter = 4000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-intervention",
   "metadata": {},
   "source": [
    "# (6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "revised-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.95\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print('정확도 : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-preparation",
   "metadata": {},
   "source": [
    "# 회고\n",
    "## - 재현율, 정밀도, f1-score가 거의 비슷하게 나와서 처음에는 코드에 문제가 있는 줄 알았으나, 딱히 문제점을 발견하지는 못했다.\n",
    "\n",
    "## - 모델들 중에서 SVM의 성능이 가장 좋아보인다. \n",
    "\n",
    "## - SVM은 Support Vector와 Hyperplane(초평면)을 이용한 알고리즘으로 어느 한쪽에 치우치지 않게, 즉 마진이 제일 적게 분류하는 방식이다.\n",
    "\n",
    "## - Decision Tree가 가장 성능이 안 좋아 보여서, 과접합이 문제인 줄 알고 max_dapth를 바꿔보았다. max_depth가 8일때에 결과가 제일 좋았지만, 다른 모델들보다는 결과가 좋지 않다.\n",
    "\n",
    "## - 모델을 평가할때는 정확도를 이용하여, 전체 샘플 중에서 맞게 예측한 샘플 수의 비율을 나타냈다. \n",
    "\n",
    "## - 로지스틱 회귀에서 반복 횟수에 관한 오류가 발생해서 4000으로 늘리니깐 해결되었다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
